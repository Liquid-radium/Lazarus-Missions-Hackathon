{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10917832,"sourceType":"datasetVersion","datasetId":6787343}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T08:48:35.590584Z","iopub.execute_input":"2025-03-10T08:48:35.590867Z","iopub.status.idle":"2025-03-10T08:48:35.608238Z","shell.execute_reply.started":"2025-03-10T08:48:35.590827Z","shell.execute_reply":"2025-03-10T08:48:35.607530Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/sentimenttt/TrainingSet.csv\n/kaggle/input/sentimenttt/TestSet.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Import necessary libraries\nimport re\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nimport keras\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nimport math\nimport nltk\n\nfrom sklearn.model_selection import train_test_split\n\n\nfrom transformers import AutoTokenizer, AutoModel\nfrom tqdm import tqdm\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Masking\nfrom tensorflow.keras.layers import (\n    LSTM, Dense, Dropout, BatchNormalization, \n    Bidirectional, Reshape\n)\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.regularizers import l2\nfrom sklearn.metrics import classification_report, accuracy_score\nimport tensorflow as tf\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T08:48:38.151205Z","iopub.execute_input":"2025-03-10T08:48:38.151503Z","iopub.status.idle":"2025-03-10T08:49:00.723605Z","shell.execute_reply.started":"2025-03-10T08:48:38.151479Z","shell.execute_reply":"2025-03-10T08:49:00.722944Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/sentimenttt/TrainingSet.csv')\ndata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T08:49:00.724509Z","iopub.execute_input":"2025-03-10T08:49:00.725025Z","iopub.status.idle":"2025-03-10T08:49:01.060788Z","shell.execute_reply.started":"2025-03-10T08:49:00.724999Z","shell.execute_reply":"2025-03-10T08:49:01.059942Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"       Unnamed: 0                                            Comment Sentiment\n0               0  Este produto com o novo tipo de bateria de lit...  Negative\n1               1  très déçue!! L’empreinte et le tactile ne fonc...  Negative\n2               2  Fui a pasar un fin de semana y decidí este hot...  Negative\n3               3  Para ser un hotel del 4 estrellas, deja bastan...  Negative\n4               4  Кормят вкусно, еда разнообразная, фрукты на уж...   Neutral\n...           ...                                                ...       ...\n28735       29295  Un très beau stylo caméra le son et l'image so...  Positive\n28736       29296   пришло быстро,но маломерка в ширину рост подошел  Positive\n28737       29297     Ne vaut pas plus que le prix on verra la durée   Neutral\n28738       29298                               Нормальный картофель   Neutral\n28739       29299  Станция небольшая, особо не погуляешь. Погли б...   Neutral\n\n[28740 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Comment</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Este produto com o novo tipo de bateria de lit...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>très déçue!! L’empreinte et le tactile ne fonc...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Fui a pasar un fin de semana y decidí este hot...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Para ser un hotel del 4 estrellas, deja bastan...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Кормят вкусно, еда разнообразная, фрукты на уж...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>28735</th>\n      <td>29295</td>\n      <td>Un très beau stylo caméra le son et l'image so...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>28736</th>\n      <td>29296</td>\n      <td>пришло быстро,но маломерка в ширину рост подошел</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>28737</th>\n      <td>29297</td>\n      <td>Ne vaut pas plus que le prix on verra la durée</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>28738</th>\n      <td>29298</td>\n      <td>Нормальный картофель</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>28739</th>\n      <td>29299</td>\n      <td>Станция небольшая, особо не погуляешь. Погли б...</td>\n      <td>Neutral</td>\n    </tr>\n  </tbody>\n</table>\n<p>28740 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"!pip install transformers datasets torch pandas scikit-learn xgboost nltk tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T08:49:32.712300Z","iopub.execute_input":"2025-03-10T08:49:32.712597Z","iopub.status.idle":"2025-03-10T08:49:37.290494Z","shell.execute_reply.started":"2025-03-10T08:49:32.712575Z","shell.execute_reply":"2025-03-10T08:49:37.289432Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.17.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')  # For lemmatization\nnltk.download('omw-1.4')  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T08:49:40.226069Z","iopub.execute_input":"2025-03-10T08:49:40.226397Z","iopub.status.idle":"2025-03-10T08:49:40.668352Z","shell.execute_reply.started":"2025-03-10T08:49:40.226370Z","shell.execute_reply":"2025-03-10T08:49:40.667517Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"Preprocessing in 2 steps ( 2 cells below) for better accuracy","metadata":{}},{"cell_type":"code","source":"\n!pip install tqdm\n\n# Import tqdm and enable it for pandas\nfrom tqdm import tqdm\ntqdm.pandas() \n\n# Load dataset\ndata = pd.read_csv(\"/kaggle/input/sentimenttt/TrainingSet.csv\")  \ndata = data.dropna(subset=['Comment'])  # Remove missing values\n\n\ndef preprocess_text(text):\n    if pd.isna(text):\n        return \"\"\n    # Preserve original characters, only lowercasing and whitespace cleanup\n    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with single\n    return text.strip().lower()\n\n# Apply preprocessing\ndata['Processed_Comment'] = data['Comment'].apply(preprocess_text)\n\n#  Lemmatization \nw_tokenizer = nltk.tokenize.WhitespaceTokenizer()\nlemmatizer = nltk.stem.WordNetLemmatizer()\n\ndef lemmatize_text(text):\n    if not text or pd.isna(text):\n        return \"\"\n    lemmatized_words = []\n    for w in w_tokenizer.tokenize(text):\n        try:\n            lemma = lemmatizer.lemmatize(w)\n            lemmatized_words.append(lemma)\n        except:\n            lemmatized_words.append(w)\n    return \" \".join(lemmatized_words)\n\n# Apply lemmatization with progress bar\ndata['Processed_Comment'] = data['Processed_Comment'].progress_apply(lemmatize_text)\n\n\nprint(data.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T08:49:44.405252Z","iopub.execute_input":"2025-03-10T08:49:44.405537Z","iopub.status.idle":"2025-03-10T09:01:52.149463Z","shell.execute_reply.started":"2025-03-10T08:49:44.405515Z","shell.execute_reply":"2025-03-10T09:01:52.148360Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28740/28740 [12:03<00:00, 39.70it/s]","output_type":"stream"},{"name":"stdout","text":"   Unnamed: 0                                            Comment Sentiment  \\\n0           0  Este produto com o novo tipo de bateria de lit...  Negative   \n1           1  très déçue!! L’empreinte et le tactile ne fonc...  Negative   \n2           2  Fui a pasar un fin de semana y decidí este hot...  Negative   \n3           3  Para ser un hotel del 4 estrellas, deja bastan...  Negative   \n4           4  Кормят вкусно, еда разнообразная, фрукты на уж...   Neutral   \n\n                                   Processed_Comment  \n0  este produto com o novo tipo de bateria de lit...  \n1  très déçue!! l’empreinte et le tactile ne fonc...  \n2  fui a pasar un fin de semana y decidí este hot...  \n3  para ser un hotel del 4 estrellas, deja bastan...  \n4  кормят вкусно, еда разнообразная, фрукты на уж...  \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def clean_text(text):\n    if pd.isna(text):\n        return \"\"\n    text = re.sub(r'\\s+', ' ', text)\n    return text.strip().lower()\n\n# Lemmatization\nw_tokenizer = nltk.tokenize.WhitespaceTokenizer()\nlemmatizer = nltk.stem.WordNetLemmatizer()\n\ndef lemma_processing(text):\n    if not text or pd.isna(text):\n        return \"\"\n    lemmatized_words = []\n    for w in w_tokenizer.tokenize(text):\n        try:\n            lemma = lemmatizer.lemmatize(w)\n            lemmatized_words.append(lemma)\n        except:\n            lemmatized_words.append(w)\n    return \" \".join(lemmatized_words)\n\n# Apply preprocessing and lemmatization\ndata['Processed_Comment'] = data['Comment'].apply(clean_text)\ndata['Processed_Comment'] = data['Processed_Comment'].progress_apply(lemma_processing)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:01:54.603683Z","iopub.execute_input":"2025-03-10T09:01:54.604001Z","iopub.status.idle":"2025-03-10T09:13:58.539420Z","shell.execute_reply.started":"2025-03-10T09:01:54.603972Z","shell.execute_reply":"2025-03-10T09:13:58.538561Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 28740/28740 [12:03<00:00, 39.73it/s]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"Used Roberta model in below cell for only embedding generation(as said in rules) but not for prediction****","metadata":{}},{"cell_type":"code","source":"import torch\nmodel_name = \"xlm-roberta-base\"  # Enhanced multilingual model for pretrained embedding only\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nbert_model = AutoModel.from_pretrained(model_name)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nbert_model = bert_model.to(device)\n\n#  Embedding Generation \ndef batch_embeddings(texts, batch_size=32):\n    bert_model.eval()\n    all_embeddings = []\n    \n    for i in tqdm(range(0, len(texts), batch_size)):\n        batch = texts[i:i+batch_size].tolist()\n        inputs = tokenizer(\n            batch, \n            padding=True, \n            truncation=True, \n            max_length=128, \n            return_tensors=\"pt\"\n        ).to(device)\n        \n        with torch.no_grad():\n            outputs = bert_model(**inputs)\n        \n       \n        cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n        all_embeddings.append(cls_embeddings)\n    \n    return np.concatenate(all_embeddings, axis=0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:23:05.791097Z","iopub.execute_input":"2025-03-10T09:23:05.791507Z","iopub.status.idle":"2025-03-10T09:23:08.093895Z","shell.execute_reply.started":"2025-03-10T09:23:05.791476Z","shell.execute_reply":"2025-03-10T09:23:08.092981Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Generate embeddings\nembeddings = batch_embeddings(data['Processed_Comment'])\n\n\nlabel_encoder = LabelEncoder()\nlabels = label_encoder.fit_transform(data['Sentiment'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:23:11.246181Z","iopub.execute_input":"2025-03-10T09:23:11.246469Z","iopub.status.idle":"2025-03-10T09:26:15.363365Z","shell.execute_reply.started":"2025-03-10T09:23:11.246447Z","shell.execute_reply":"2025-03-10T09:26:15.362427Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 899/899 [03:04<00:00,  4.88it/s]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"#  Split dataset\nX_train, X_val, y_train, y_val = train_test_split(\n    embeddings, \n    labels, \n    test_size=0.2, \n    random_state=42,\n    stratify=labels  \n)\n\n# Reshape embeddings  model input\nX_train = X_train.reshape(X_train.shape[0], X_train.shape[1])\nX_val = X_val.reshape(X_val.shape[0], X_val.shape[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:27:05.607520Z","iopub.execute_input":"2025-03-10T09:27:05.607821Z","iopub.status.idle":"2025-03-10T09:27:05.649658Z","shell.execute_reply.started":"2025-03-10T09:27:05.607798Z","shell.execute_reply":"2025-03-10T09:27:05.648982Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Define Neural Network Model\ndef create_advanced_model(input_shape, num_classes):\n    model = Sequential([\n        # Input layer\n        Dense(1024, activation='relu', input_shape=input_shape),\n        BatchNormalization(),\n        Dropout(0.4),\n\n        Dense(512, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.3),\n        \n        Dense(256, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.4),\n        \n        Dense(128, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.3),\n        \n        Dense(64, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.2),\n        \n        # Output layer with softmax for multi-class classification\n        Dense(num_classes, activation='softmax')\n    ])\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:27:10.548520Z","iopub.execute_input":"2025-03-10T09:27:10.548801Z","iopub.status.idle":"2025-03-10T09:27:10.554051Z","shell.execute_reply.started":"2025-03-10T09:27:10.548779Z","shell.execute_reply":"2025-03-10T09:27:10.553111Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"\ninput_shape = (X_train.shape[1],)  # Input shape for dense layers\nnum_classes = len(label_encoder.classes_)\n\n# Create and Compile Model using Optimizer\nmodel = create_advanced_model(input_shape, num_classes)\nmodel.compile(\n    optimizer=Adam(learning_rate=0.0003, clipvalue=1.0), \n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=15,  # Increased patience\n    restore_best_weights=True,\n    min_delta=0.0005\n)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss', \n    factor=0.4,  \n    patience=7,\n    min_lr=0.000005\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:27:14.889548Z","iopub.execute_input":"2025-03-10T09:27:14.889850Z","iopub.status.idle":"2025-03-10T09:27:14.987287Z","shell.execute_reply.started":"2025-03-10T09:27:14.889825Z","shell.execute_reply":"2025-03-10T09:27:14.986473Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Model Training \nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    epochs=150,  \n    batch_size=64,  \n    callbacks=[early_stopping, reduce_lr],\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:27:17.632599Z","iopub.execute_input":"2025-03-10T09:27:17.632909Z","iopub.status.idle":"2025-03-10T09:28:17.911114Z","shell.execute_reply.started":"2025-03-10T09:27:17.632884Z","shell.execute_reply":"2025-03-10T09:28:17.910240Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.5050 - loss: 1.2197 - val_accuracy: 0.6129 - val_loss: 0.8186 - learning_rate: 3.0000e-04\nEpoch 2/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6762 - loss: 0.7602 - val_accuracy: 0.7281 - val_loss: 0.6337 - learning_rate: 3.0000e-04\nEpoch 3/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6943 - loss: 0.6986 - val_accuracy: 0.7354 - val_loss: 0.5984 - learning_rate: 3.0000e-04\nEpoch 4/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7089 - loss: 0.6657 - val_accuracy: 0.7512 - val_loss: 0.5847 - learning_rate: 3.0000e-04\nEpoch 5/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7191 - loss: 0.6492 - val_accuracy: 0.7498 - val_loss: 0.5844 - learning_rate: 3.0000e-04\nEpoch 6/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7233 - loss: 0.6235 - val_accuracy: 0.7444 - val_loss: 0.5886 - learning_rate: 3.0000e-04\nEpoch 7/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7326 - loss: 0.6158 - val_accuracy: 0.7531 - val_loss: 0.5703 - learning_rate: 3.0000e-04\nEpoch 8/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7337 - loss: 0.6074 - val_accuracy: 0.7215 - val_loss: 0.6221 - learning_rate: 3.0000e-04\nEpoch 9/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7392 - loss: 0.5970 - val_accuracy: 0.7484 - val_loss: 0.5865 - learning_rate: 3.0000e-04\nEpoch 10/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7387 - loss: 0.5964 - val_accuracy: 0.7538 - val_loss: 0.5694 - learning_rate: 3.0000e-04\nEpoch 11/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7432 - loss: 0.5904 - val_accuracy: 0.7364 - val_loss: 0.6081 - learning_rate: 3.0000e-04\nEpoch 12/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7499 - loss: 0.5798 - val_accuracy: 0.6743 - val_loss: 0.7959 - learning_rate: 3.0000e-04\nEpoch 13/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7473 - loss: 0.5830 - val_accuracy: 0.7530 - val_loss: 0.5741 - learning_rate: 3.0000e-04\nEpoch 14/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7436 - loss: 0.5815 - val_accuracy: 0.7547 - val_loss: 0.5692 - learning_rate: 3.0000e-04\nEpoch 15/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7522 - loss: 0.5740 - val_accuracy: 0.7336 - val_loss: 0.5976 - learning_rate: 3.0000e-04\nEpoch 16/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7591 - loss: 0.5594 - val_accuracy: 0.7183 - val_loss: 0.6701 - learning_rate: 3.0000e-04\nEpoch 17/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7523 - loss: 0.5727 - val_accuracy: 0.7550 - val_loss: 0.5747 - learning_rate: 3.0000e-04\nEpoch 18/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7517 - loss: 0.5731 - val_accuracy: 0.7049 - val_loss: 0.6539 - learning_rate: 3.0000e-04\nEpoch 19/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7562 - loss: 0.5637 - val_accuracy: 0.7336 - val_loss: 0.6173 - learning_rate: 3.0000e-04\nEpoch 20/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.5582 - val_accuracy: 0.7444 - val_loss: 0.5808 - learning_rate: 3.0000e-04\nEpoch 21/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7614 - loss: 0.5548 - val_accuracy: 0.7128 - val_loss: 0.6270 - learning_rate: 3.0000e-04\nEpoch 22/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7680 - loss: 0.5423 - val_accuracy: 0.7651 - val_loss: 0.5545 - learning_rate: 1.2000e-04\nEpoch 23/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7673 - loss: 0.5380 - val_accuracy: 0.7594 - val_loss: 0.5586 - learning_rate: 1.2000e-04\nEpoch 24/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7758 - loss: 0.5201 - val_accuracy: 0.7582 - val_loss: 0.5590 - learning_rate: 1.2000e-04\nEpoch 25/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7758 - loss: 0.5258 - val_accuracy: 0.7603 - val_loss: 0.5831 - learning_rate: 1.2000e-04\nEpoch 26/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7722 - loss: 0.5305 - val_accuracy: 0.7627 - val_loss: 0.5572 - learning_rate: 1.2000e-04\nEpoch 27/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7678 - loss: 0.5324 - val_accuracy: 0.7568 - val_loss: 0.5632 - learning_rate: 1.2000e-04\nEpoch 28/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7813 - loss: 0.5144 - val_accuracy: 0.7604 - val_loss: 0.5593 - learning_rate: 1.2000e-04\nEpoch 29/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7822 - loss: 0.5172 - val_accuracy: 0.7644 - val_loss: 0.5578 - learning_rate: 1.2000e-04\nEpoch 30/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7779 - loss: 0.5180 - val_accuracy: 0.7634 - val_loss: 0.5538 - learning_rate: 4.8000e-05\nEpoch 31/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7854 - loss: 0.4997 - val_accuracy: 0.7542 - val_loss: 0.5740 - learning_rate: 4.8000e-05\nEpoch 32/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7782 - loss: 0.5132 - val_accuracy: 0.7606 - val_loss: 0.5612 - learning_rate: 4.8000e-05\nEpoch 33/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7803 - loss: 0.5075 - val_accuracy: 0.7597 - val_loss: 0.5555 - learning_rate: 4.8000e-05\nEpoch 34/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7853 - loss: 0.4962 - val_accuracy: 0.7630 - val_loss: 0.5565 - learning_rate: 4.8000e-05\nEpoch 35/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7803 - loss: 0.5045 - val_accuracy: 0.7610 - val_loss: 0.5576 - learning_rate: 4.8000e-05\nEpoch 36/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7770 - loss: 0.5121 - val_accuracy: 0.7585 - val_loss: 0.5620 - learning_rate: 4.8000e-05\nEpoch 37/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7848 - loss: 0.5092 - val_accuracy: 0.7597 - val_loss: 0.5636 - learning_rate: 4.8000e-05\nEpoch 38/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7836 - loss: 0.5061 - val_accuracy: 0.7604 - val_loss: 0.5607 - learning_rate: 1.9200e-05\nEpoch 39/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7779 - loss: 0.5068 - val_accuracy: 0.7575 - val_loss: 0.5632 - learning_rate: 1.9200e-05\nEpoch 40/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7854 - loss: 0.4948 - val_accuracy: 0.7594 - val_loss: 0.5629 - learning_rate: 1.9200e-05\nEpoch 41/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7881 - loss: 0.4942 - val_accuracy: 0.7590 - val_loss: 0.5640 - learning_rate: 1.9200e-05\nEpoch 42/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7884 - loss: 0.5004 - val_accuracy: 0.7577 - val_loss: 0.5634 - learning_rate: 1.9200e-05\nEpoch 43/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7851 - loss: 0.4930 - val_accuracy: 0.7601 - val_loss: 0.5659 - learning_rate: 1.9200e-05\nEpoch 44/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7918 - loss: 0.4846 - val_accuracy: 0.7596 - val_loss: 0.5635 - learning_rate: 1.9200e-05\nEpoch 45/150\n\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7909 - loss: 0.4862 - val_accuracy: 0.7601 - val_loss: 0.5633 - learning_rate: 7.6800e-06\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Evaluation\nval_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\nprint(f\"Validation Accuracy: {val_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:29:38.100994Z","iopub.execute_input":"2025-03-10T09:29:38.101458Z","iopub.status.idle":"2025-03-10T09:29:39.436283Z","shell.execute_reply.started":"2025-03-10T09:29:38.101422Z","shell.execute_reply":"2025-03-10T09:29:39.435432Z"}},"outputs":[{"name":"stdout","text":"Validation Accuracy: 0.7634\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"Processing of test data described below","metadata":{}},{"cell_type":"code","source":"# Load Test Dataset\ntest_data = pd.read_csv(\"/kaggle/input/sentimenttt/TestSet.csv\")\ntest_data = test_data.dropna(subset=['Comment'])\n\n# Preprocess test data\ntest_data['Processed_Comment'] = test_data['Comment'].apply(preprocess_text)\n\n# Generate embeddings for test data\ntest_embeddings = batch_embeddings(test_data['Processed_Comment'])\n\n# Reshape test embeddings for model input\ntest_embeddings = test_embeddings.reshape(test_embeddings.shape[0], test_embeddings.shape[1])\n\n# Make predictions\ntest_predictions = model.predict(test_embeddings)\ntest_pred_labels = np.argmax(test_predictions, axis=1)\n\n# Convert predictions back to original labels\npredicted_labels = label_encoder.inverse_transform(test_pred_labels)\n\n# Create submission DataFrame\nsubmission = pd.DataFrame({\n    'index': test_data.index,\n    'sentiment': predicted_labels\n})\n\n# Save submission to CSV\noutput_path = \"/kaggle/working/submission.csv\"\nsubmission.to_csv(output_path, index=False)\n\nprint(f\"Submission file saved to {output_path}\")\nprint(submission.head())\n\n\nprint(\"\\nPredicted Sentiment Distribution:\")\nprint(submission['sentiment'].value_counts(normalize=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:29:48.973767Z","iopub.execute_input":"2025-03-10T09:29:48.974061Z","iopub.status.idle":"2025-03-10T09:31:22.820707Z","shell.execute_reply.started":"2025-03-10T09:29:48.974038Z","shell.execute_reply":"2025-03-10T09:31:22.819837Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 452/452 [01:32<00:00,  4.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\nSubmission file saved to /kaggle/working/submission.csv\n   index sentiment\n0      0  Negative\n1      1   Neutral\n2      2  Positive\n3      3  Negative\n4      4   Neutral\n\nPredicted Sentiment Distribution:\nsentiment\nPositive    0.503457\nNegative    0.292906\nNeutral     0.203637\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T11:53:33.821877Z","iopub.execute_input":"2025-03-05T11:53:33.822168Z","iopub.status.idle":"2025-03-05T11:53:33.826671Z","shell.execute_reply.started":"2025-03-05T11:53:33.822144Z","shell.execute_reply":"2025-03-05T11:53:33.825937Z"}},"outputs":[],"execution_count":10}]}